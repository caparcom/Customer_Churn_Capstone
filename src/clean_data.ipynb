{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0203361b",
   "metadata": {},
   "source": [
    "# What Public School characteristics point towards a \"high strained system\" ie high student teacher ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c45de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from utils import db_connect\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "engine = db_connect()\n",
    "\n",
    "# bring in the data\n",
    "main_df = pd.read_sql('SELECT * FROM combined_data', con=engine)\n",
    "\n",
    "# function to mark whether a school was operational all five years of data\n",
    "# creates our 'Currently operational' feature\n",
    "def mark_always_operational(main_df):\n",
    "    \n",
    "    total_years = main_df['SURVYEAR'].nunique()\n",
    "    \n",
    "    main_df['SY_STATUS_TEXT'] = main_df['SY_STATUS_TEXT'].str.strip()\n",
    "    \n",
    "    operational_counts = (\n",
    "        main_df[main_df['SY_STATUS_TEXT'] == 'Currently operational']\n",
    "        .groupby('NCESSCH')['SURVYEAR']\n",
    "        .nunique()\n",
    "    )\n",
    "    \n",
    "    always_operational_schools = operational_counts[operational_counts == total_years].index\n",
    "    \n",
    "    main_df['concurrently_operational'] = main_df['NCESSCH'].isin(always_operational_schools)\n",
    "    \n",
    "    return main_df\n",
    "\n",
    "# apply the function\n",
    "mark_always_operational(main_df=main_df)\n",
    "\n",
    "# drop records that were not fully operational across all five years\n",
    "main_df = main_df[main_df['concurrently_operational'] != False]\n",
    "\n",
    "# strip whitespace\n",
    "for col in main_df.select_dtypes(include=[\"string\"]).columns:\n",
    "    main_df[col] = main_df[col].str.strip()\n",
    "\n",
    "# begin defining data type conversion processes\n",
    "# Change columns to floats\n",
    "float_cols = [\"X\", \"Y\", \"LATCOD\", \"LONCOD\", \"FTE\", \"STUTERATIO\"]\n",
    "\n",
    "# change columns to int\n",
    "int_cols = [\n",
    "    \"OBJECTID\", \"GSLO\", \"GSHI\",\n",
    "    \"TOTFRL\", \"FRELCH\", \"REDLCH\", \"DIRECTCERT\",\n",
    "    \"PK\", \"KG\", \"G01\", \"G02\", \"G03\", \"G04\", \"G05\", \"G06\",\n",
    "    \"G07\", \"G08\", \"G09\", \"G10\", \"G11\", \"G12\", \"G13\",\n",
    "    \"UG\", \"AE\",\n",
    "    \"TOTMENROL\", \"TOTFENROL\", \"TOTAL\", \"MEMBER\",\n",
    "    \"AMALM\", \"AMALF\", \"AM\",\n",
    "    \"ASALM\", \"ASALF\", \"AS\",\n",
    "    \"BLALM\", \"BLALF\", \"BL\",\n",
    "    \"HPALM\", \"HPALF\", \"HP\",\n",
    "    \"HIALM\", \"HIALF\", \"HI\",\n",
    "    \"TRALM\", \"TRALF\", \"TR\",\n",
    "    \"WHALM\", \"WHALF\", \"WH\"\n",
    "]\n",
    "\n",
    "# Change columns to strings\n",
    "string_cols = [\n",
    "    \"NCESSCH\", \"SURVYEAR\", \"STABR\", \"LEAID\", \"ST_LEAID\",\n",
    "    \"LEA_NAME\", \"SCH_NAME\",\n",
    "    \"LSTREET1\", \"LSTREET2\", \"LCITY\", \"LSTATE\",\n",
    "    \"LZIP\", \"LZIP4\", \"PHONE\",\n",
    "    \"VIRTUAL\", \"SCHOOL_LEVEL\", \"SCHOOL_TYPE_TEXT\",\n",
    "    \"STATUS\", \"SY_STATUS_TEXT\", \"ULOCALE\", \"NMCNTY\",\n",
    "    \"CHARTER_TEXT\", \"LSTREET3\", \"TITLEI\", \"STITLEI\", \"MAGNET_TEXT\"\n",
    "]\n",
    " \n",
    "# -1 or M -> Indicates that the data are missing.\n",
    "\n",
    "# -2 or N -> Indicates that the data are not applicable.\n",
    "\n",
    "# -9 -> Indicates that the data do not meet NCES data quality standards.\n",
    "\n",
    "# function to clean NCES error codes\n",
    "def clean_nces_error_codes(main_df, cols):\n",
    "    error_values = [\"M\", \"-1\", \"-9\", \"Missing\", -1, -9\n",
    "]\n",
    "    main_df[cols] = main_df[cols].replace(error_values, np.nan)\n",
    "    return main_df\n",
    "\n",
    "# clean ALL columns \n",
    "cols = float_cols + int_cols + string_cols\n",
    "main_df = clean_nces_error_codes(main_df, cols)\n",
    "\n",
    "# convert floats safely\n",
    "for col in float_cols:\n",
    "    main_df[col] = pd.to_numeric(main_df[col], errors=\"coerce\")\n",
    "\n",
    "    # convert ints safely\n",
    "for col in int_cols:\n",
    "    main_df[col] = pd.to_numeric(main_df[col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # convert strings\n",
    "for col in string_cols:\n",
    "    main_df[col] = main_df[col].astype(\"string\")\n",
    "\n",
    "    # round coordinates\n",
    "main_df[\"LATCOD\"] = main_df[\"LATCOD\"].round(4)\n",
    "main_df[\"LONCOD\"] = main_df[\"LONCOD\"].round(4)\n",
    "\n",
    "# extract start Year - convert to int for sorting\n",
    "main_df['SURVYEAR'] = main_df['SURVYEAR'].str[:4].astype(int)\n",
    "\n",
    "# removing virtual schools\n",
    "main_df = main_df[main_df['VIRTUAL'].isin(['Not Virtual', 'Not a virtual school'])]\n",
    "\n",
    "# drop the virtual feature\n",
    "main_df.drop(columns='VIRTUAL', inplace=True)\n",
    "\n",
    "# only keeping 'regular' public schools, removing: [ 'Career and Technical School',\n",
    "# 'Special education school', 'Alternative Education School',\n",
    "# 'Alternative/other school', 'Vocational school']\n",
    "main_df = main_df[main_df['SCHOOL_TYPE_TEXT'].isin(['Regular school', 'Regular School'])]\n",
    "\n",
    "# drop the SCHOOL_TYPE_TEXT feature\n",
    "main_df.drop(columns='SCHOOL_TYPE_TEXT', inplace=True)\n",
    "\n",
    "# replace na values with 0\n",
    "main_df = main_df.fillna(0)\n",
    "\n",
    "# Checking records against all five years\n",
    "counts = main_df[\"NCESSCH\"].value_counts()\n",
    "keep_ids = counts[counts == 5].index\n",
    "main_df = main_df[main_df[\"NCESSCH\"].isin(keep_ids)].copy()\n",
    "\n",
    "print(f\"1. main_df shape: {main_df.shape}\")\n",
    "\n",
    "# Simplify ULOCALE\n",
    "main_df[\"locale_category\"] = main_df[\"ULOCALE\"].str.split(\"-\").str[1].str.split(\":\").str[0]\n",
    "\n",
    "# Drop the ULOCALE feature because we now have our simplified locale_category feature\n",
    "main_df.drop(columns='ULOCALE', inplace=True)\n",
    "\n",
    "# Title I rough breakdown:\n",
    "\n",
    "# Participating:\n",
    "# 1 - Yes - School participates in Title I funding / programs\n",
    "# 5 - Title I schoolwide school - ENTIRE school recieves Title I support. Funds can be used for all students\n",
    "# 2 - Title I targeted assistance school - Only SPECIFIC eligible students recieve services (usually low-income or academically at risk)\n",
    "\n",
    "# Eligible, but no program running:\n",
    "# 4 - Title I schoolwide eligible school - no program - Enough low-income students to qualify for schoolwide funding, but not using it\n",
    "# 1 - Title I targeted assistance eligible school - No program - Eligible for targeted assistance but not participating\n",
    "\n",
    "# Hybrid\n",
    "# 3 Title I schoolwide eligible - Title I targeted assitance program - School qualifies for schoolwide funding but has chosen to run only a targeted program\n",
    "\n",
    "# Explicit non-participation\n",
    "# 2 - No - School does not participate\n",
    "# 6 - Not a Title I school\n",
    "\n",
    "# 0\n",
    "# 0 - Assuming missing, unknown, or not reported\n",
    "\n",
    "\n",
    "# Conceptual differences:\n",
    "# Schoolwide = whole school qualifies = High funding flexibility - Typical poverty threshold >= 40% low-income\n",
    "# Targeted = only some students qualify = Limited funding flexibility - lower threshold for poverty\n",
    "\n",
    "# standardize TITLEI\n",
    "schoolwide = ['1-Yes', '5-Title I schoolwide school']\n",
    "targeted = ['2-Title I targeted assistance school', '3-Title I schoolwide eligible-Title I targeted assistance program']\n",
    "elig_no_participate = ['4-Title I schoolwide eligible school-No program', \n",
    "                       '1-Title I targeted assistance eligible school-No program']\n",
    "not_elig = ['2-No', '6-Not a Title I school']\n",
    "missing = [0]\n",
    "\n",
    "def group_titlei(col_TITLEI):\n",
    "    if col_TITLEI in missing:\n",
    "        return \"Unknown\"\n",
    "    elif col_TITLEI in schoolwide:\n",
    "        return \"Schoolwide\"\n",
    "    elif col_TITLEI in targeted:\n",
    "        return \"Targeted\"\n",
    "    elif col_TITLEI in elig_no_participate:\n",
    "        return \"Eligible_No_Program\"\n",
    "    elif col_TITLEI in not_elig:\n",
    "        return \"Not_Eligible\"\n",
    "    else:\n",
    "        return \"Error\"\n",
    "    \n",
    "# apply the above function to main_df\n",
    "main_df['TITLEI_GROUPED'] = main_df['TITLEI'].apply(group_titlei)\n",
    "\n",
    "# standardize STITLEI\n",
    "STITLEI_yes = ['1-Yes', 'Yes']\n",
    "STITLEI_no = ['2-No', 'No']\n",
    "STITLEI_unknown = [0]\n",
    "\n",
    "def standardize_STITLEI(col_STITLEI):\n",
    "    if col_STITLEI in STITLEI_yes:\n",
    "        return 'Yes'\n",
    "    elif col_STITLEI in STITLEI_no:\n",
    "        return 'No'\n",
    "    elif col_STITLEI in STITLEI_unknown:\n",
    "        return 'Unknown'\n",
    "    else:\n",
    "        return 'Error'\n",
    "    \n",
    "# apply the above function to main_df    \n",
    "main_df['STITLEI'] = main_df['STITLEI'].apply(standardize_STITLEI)\n",
    "\n",
    "# update the contradticions between TITLEI and STITLEI (Updating the below to 'Targeted' group instead of 'Schoolwide')\n",
    "main_df.loc[(main_df['TITLEI'] == '1-Yes') & (main_df['STITLEI'] == 'No'), 'TITLEI_GROUPED'] = 'Targeted'\n",
    "\n",
    "# Checking records against all five years\n",
    "counts = main_df[\"NCESSCH\"].value_counts()\n",
    "keep_ids = counts[counts == 5].index\n",
    "main_df = main_df[main_df[\"NCESSCH\"].isin(keep_ids)].copy()\n",
    "\n",
    "print(f\"2. main_df shape: {main_df.shape}\")\n",
    "\n",
    "# further filtering on positive student teacher ratios\n",
    "main_df = main_df[main_df['STUTERATIO'] != 0.0]\n",
    "\n",
    "# define additional redundant columns\n",
    "redundant_cols = ['X', 'Y', 'OBJECTID', 'ST_LEAID', 'LSTREET1', 'LSTREET2', 'LSTREET3', \n",
    "                  'LZIP4', 'PHONE', 'AMALM', 'AMALF', 'ASALM', 'ASALF', \n",
    "                  'BLALM', 'BLALF', 'HPALM', 'HPALF', 'HIALM', 'HIALF', 'TRALM', 'TRALF', \n",
    "                  'WHALM', 'WHALF', 'STABR', 'LCITY', 'LSTATE', 'LZIP', 'SCHOOL_LEVEL', 'GSLO', 'GSHI'\n",
    "                  , 'STATUS', 'SY_STATUS_TEXT', 'NMCNTY', 'DIRECTCERT', 'AE', 'TOTFENROL', 'TOTMENROL',\n",
    "                  'concurrently_operational', 'TITLEI', 'STITLEI', 'MEMBER']\n",
    "\n",
    "# drop additional redundant cols\n",
    "main_df = main_df.drop(columns=redundant_cols)\n",
    "\n",
    "# remove the large Alaska homeschool support program from data set\n",
    "main_df[main_df['NCESSCH'] != '20013000253']\n",
    "\n",
    "# trim the top percentile off\n",
    "def trim_top_percentile(df, col=\"STUTERATIO\", percentile=0.99):\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Calculate cutoff\n",
    "    cutoff = df[col].quantile(percentile)\n",
    "\n",
    "    # Count rows before trimming\n",
    "    before_count = df.shape[0]\n",
    "\n",
    "    # Trim\n",
    "    df_trimmed = df[df[col] <= cutoff].copy()\n",
    "\n",
    "    after_count = df_trimmed.shape[0]\n",
    "\n",
    "    print(f\"{percentile*100}th percentile cutoff: {cutoff:.2f}\")\n",
    "    print(f\"Rows before: {before_count}\")\n",
    "    print(f\"Rows after: {after_count}\")\n",
    "    print(f\"Rows removed: {before_count - after_count}\")\n",
    "\n",
    "    print(\"\\nTop values after trimming:\")\n",
    "    print(\n",
    "        df_trimmed.sort_values(col, ascending=False)[\n",
    "            [\"NCESSCH\", \"SURVYEAR\", \"FTE\", col]\n",
    "        ].head(10)\n",
    "    )\n",
    "\n",
    "    return df_trimmed\n",
    "\n",
    "# apply the above function to main_df\n",
    "main_df = trim_top_percentile(main_df, col=\"STUTERATIO\", percentile=0.99)\n",
    "\n",
    "# trim the bottom percentile off\n",
    "def trim_bottom_percentile(df, col=\"STUTERATIO\", percentile=0.01):\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Calculate cutoff\n",
    "    cutoff = df[col].quantile(percentile)\n",
    "\n",
    "    # Count rows before trimming\n",
    "    before_count = df.shape[0]\n",
    "\n",
    "    # Trim bottom values\n",
    "    df_trimmed = df[df[col] >= cutoff].copy()\n",
    "\n",
    "    after_count = df_trimmed.shape[0]\n",
    "\n",
    "    print(f\"{percentile*100}th percentile cutoff: {cutoff:.2f}\")\n",
    "    print(f\"Rows before: {before_count}\")\n",
    "    print(f\"Rows after: {after_count}\")\n",
    "    print(f\"Rows removed: {before_count - after_count}\")\n",
    "\n",
    "    print(\"\\nBottom values after trimming:\")\n",
    "    print(\n",
    "        df_trimmed.sort_values(col, ascending=True)[\n",
    "            [\"NCESSCH\", \"SURVYEAR\", \"FTE\", col]\n",
    "        ].head(10)\n",
    "    )\n",
    "\n",
    "    return df_trimmed\n",
    "\n",
    "main_df = trim_bottom_percentile(main_df)\n",
    "\n",
    "# create our high-strain feature\n",
    "main_df[\"high_strain\"] = (main_df[\"STUTERATIO\"] > 20).astype(int)\n",
    "\n",
    "# updating nces error codes to No or 0 for respective columns\n",
    "values = [\"N\", \"-2\",\"Not applicable\", \"Not Applicable\",-2,]\n",
    "main_df.loc[main_df['CHARTER_TEXT'].isin(values), 'CHARTER_TEXT'] = 'No'\n",
    "main_df.loc[main_df['MAGNET_TEXT'].isin(values), 'MAGNET_TEXT'] = 'No'\n",
    "main_df.loc[main_df['FRELCH'].isin(values), 'FRELCH'] = 0\n",
    "main_df.loc[main_df['REDLCH'].isin(values), 'REDLCH'] = 0\n",
    "\n",
    "# keeping all records with 5 years of data\n",
    "counts = main_df[\"NCESSCH\"].value_counts()\n",
    "keep_ids = counts[counts == 5].index\n",
    "main_df = main_df[main_df[\"NCESSCH\"].isin(keep_ids)].copy()\n",
    "\n",
    "print(f\"3. main_df shape: {main_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4996f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above has been pushed to the database under the table name \"main_df\"\n",
    "# to read in from db:\n",
    "# main_df = pd.read_sql('SELECT * FROM main_df', con=engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
